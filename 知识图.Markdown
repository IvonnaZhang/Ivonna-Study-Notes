# 知识图

**任务要求：基于知识表示的方法有很多，模型是什么，优缺点是什么**

我们需要做的是基于图谱里已有的关系，去推理出缺失的关系

## 基于知识表示的方法

基于知识表示的方法，是最直接的一种方式。

- 知识表示学习：对知识图谱中的实体和关系学习其低维度的嵌入式表示。
- 常见的知识表示学习方法：上图涵盖了常见的知识表示学习方法，主要是以TransE法为核心，针对空间映射等场景做的改进。

### TransE

#### 核心理念

TransE 对三元组$(ｈ,ｒ,ｔ)$中的实体和关系映射到向量空间作了一些假设：

- 每一个三元组$(ｈ,ｒ,ｔ)$都能表示为$(ｈ,ｒ,ｔ)$
  - 其中，ｈ是指头实体的向量表示，ｒ是指关系的向量表示，ｔ是指尾实体的向量表示
- 通过不断调整来构建三元组（其中三元组的实体和关系都来自源知识图谱），来发现向量空间中，头实体向量ｈ加上关系ｒ等于尾实体向量ｔ的三元组，这个过程称为翻译
- 如果在向量空间这种关系成立，就说明三元组$(ｈ,ｒ,ｔ)$所代表的知识表示可以看作是正确的，以此来发现实体间新的关系，如下图所示：

![截屏2023-10-29 11.37.27](/Users/zhangyuxin/Library/Application Support/typora-user-images/截屏2023-10-29 11.37.27.png)

- TransE的功能在于：
  - 通过词向量表示知识图谱中已存在的三元组（所以TransE可以看作知识表示方法）
  - 扩大知识图谱中的关系网，扩充构建多元关系数据
    - 其中，关系数据包括单一关系数据(single-relational data)和多元关系数据(multi-relational data)
      - 单一关系通常是结构化的，可以直接进行简单的推理；多元关系则依赖于多种类型的实体和关系，因此需要一种通用的方法能够同时考虑异构关系
        - 所以TransE可以看作“活的”或“更高级的”的知识表示方法，因为可以做知识图谱上的链接预测，或作为媒介完善知识图谱

#### 主要流程

知识图谱（KG）中现存的关系构成关系集，实体构成实体集，模型抽取两个集合来构成三元组。 按照$h+r\approx t$规则做向量运算。 如果近似达到要求，则可以在两个实体间建立联系来补充完善知识图谱，通过这样的方法挖掘、发现实体间的多元关系，扩大知识图谱实体间的关系网，发挥链接预测的作用

#### 得分函数

TransE的得分函数为：

$$
f_r(h,t)=||h+r-t||_{L1/L2}
$$

#### transE算法的简单python实现

##### 训练transE

- Tbatch更新
  - 在`update_embeddings`函数中有一个`deepcopy`操作，目的就是为了批量更新。这是ML中`mini-batch SGD`的一个通用的训练知识，在实际编码时很容易忽略
- 两次更新
  - `update_embeddings`函数中，要对`correct triplet`和`corrupted triplet`都进行更新。虽然写作$( h , l , t )和( h′ , l , t′ )$，但两个三元组只有一个`entity`不同（不同时替换头尾实体），所以在每步更新时重叠的实体要更新两次（和更新relation一样），否则就会导致后一次更新覆盖前一次
- 关于L1范数的求导方法
  - 先对L2范数求导，逐元素判断正负，为正赋值为1，负则为-1
- 超参选择
  - 对`FB15k`数据集，`epoch`选了1000（其实不需要这么大，后面就没什么提高了），`nbatches`选了400（训练最快），`embedding_dim`=50, `learning_rate`=0.01, `margin`=1

##### 测试

- isFit参数
  - 区分`raw`和`filter`。`filter`会非常慢

#### transE算法的优缺点

##### 优点

- 解决多关系数据的处理问题，是一种简单高效的 KG 表示学习方法
- 能够完成多种关系的链接预测任务，能够自动且很好地捕捉推理特征
- 适合在大规模复杂的 KG 上推广，是一种有效的 KG 推理手段

##### 缺点

表达能力不足，不能够有效充分的捕捉实体对间语义关系，无法有效处理一对多、多对一、多对多的关系以及自反关系。
处理图像信息效果差、负样本三元组的质量低、嵌入模型不能快速收敛、泛化能力差、边缘识别能力…

#### transE算法的局限性

transE效果很好且非常简单，后续大量的工作都是在此基础上的改进（简称trans大礼包），传统方法已经基本不用了（有些思想还是值得借鉴的，比如矩阵分解、双线性模型）。改进大体针对以下几个问题：

- **复杂关系建模效果差。**对1-N,N-1,N-N关系，会出现冲突映射，一个实体在不同三元组内的表示融合，导致不明确甚至错误的语义信息
- **多源信息融合。** 如何充分利用知识库中的额外信息（如实体类型、实体描述）
- **关系路径建模。 **对relation之间的依赖进行建模

#### TransE的变体
TransE是知识图谱的向量化表示的基础，衍生出来了很多变体:

- TransH，AAAI2014，Knowledge graph embedding by translating on hyperplanes
- TransD，ACL2015，Knowledge graph embedding via dynamic mapping matrix
- TransA，arXiv2015，An adaptive approach for knowledge graph embedding
- TransG，arxiv2015，A Generative Mixture Model for Knowledge Graph Embedding)
- KG2E，CIKM2015，Learning to represent knowledge graphs with gaussian embedding
- TranSparse，AAAI2016，Knowledge graph completion with adaptive sparse transfer matrix

### TransH

#### 从TransE到TransH模型

对于TransE模型而言，其核心思想为：
$$
h+r=t
$$

- 其中h是头实体向量，r是关系向量，t是尾实体向量

根据这个核心公式，我们不难发现其存在着一定的局限性。比如当存在多对一关系的时候，假设 $(h_1,r,t),(h_2,r,t)$，根据TransE的假设，可以确定的是：
$$
h_1+r=t,~~h_2+r=t
$$

- 这使得$h_1,h_2$两个头实体的向量过于相近。与此同时，当存在 ( h , r , t ) , ( t , r , h ) 均在图谱中出现的时候，会计算出r=0，h=t
- 总的来说，TransE模型在处理多对一，多对多，自反关系的时候，会有很多局限性。为了解决上面的我们提到的问题。提出了TranH模型

#### 基本思想

针对每一个关系r，都给出一个超平面Wr，在Wr超平面上定义关系向量dr，在将原有的头实体h和尾实体t映射到超平面上为hr，tr。要求正确的三元组满足下面的公式：
$$
h_r+d_r=t_r
$$
用一张图来表示这个过程：

![20200213154149703](/Users/zhangyuxin/Library/Application Support/typora-user-images/20200213154149703.PNG)

#### 相对于TransE的改进

之前提到了，在TranE模型中，如果h1和h2向量都存在着同一个关系r和同一个尾实体t。那么在TransE中h1和h2是相同的(或者可以说是特别近似的)

而在TransH中，如果对于h1和h2向量都存在一个三元组(h1,r,t)和(h2,r,t)。通过TranH中关系r的超平面的映射，则有：
$$
h_{1r}+d_r=t_r,~~h_{2r}+d_r=t_r
$$
也就是说$h_1,h_2$在超平面上的映射是形同或者近似的。但是对于$h_1,h_2$本身可以是不相近的，也就是可以区分的。如下图所示：
![20200213155355271](/Users/zhangyuxin/Library/Application Support/typora-user-images/20200213155355271.PNG)

#### 得分函数

TransH的得分函数为：

$$
f_r(h,t)=||(h-w_r^Thw_r)+d_r-(t-w_r^Ttw_r)||_2^2
$$

